QueueGauge — NestJS + Neon blueprint (job queue + status + retries)

What it is

QueueGauge is a lightweight job queue backend: create jobs, track status, retry failures, and fetch a dashboard view. It’s intentionally “boring queue”—not RabbitMQ, not BullMQ—just a clean relational queue that proves you can design operational systems with correctness.


---

Shared backbone (required in every Neon-backed NestJS app)

Rule: Clients never connect to Neon directly.
Flow: Client → NestJS API → Neon (Postgres)

Identity (v1):

Client generates device_key (UUID).

Header: X-Device-Key.

API resolves device_key → user_id and scopes all data by user_id.


Server invariants

Node 20

Env-only secrets

Parameterized queries only

Safe concurrency + basic rate limits



---

Stack (pinned & stable)

NestJS (TypeScript)

Postgres: Neon

DB: pg (Pool)

DTO validation: class-validator

Config: @nestjs/config



---

Queue model goals

Deterministic job state transitions

Worker can lease jobs safely (avoid double-processing)

Retries with backoff

Dashboard endpoints that show queue health



---

Data model (Neon Postgres)

sql/001_queuegauge.sql

create extension if not exists pgcrypto;

create table if not exists users (
  id uuid primary key default gen_random_uuid(),
  device_key text not null unique,
  created_at timestamptz not null default now()
);

create type public.job_status as enum ('queued','leased','succeeded','failed','canceled');

create table if not exists jobs (
  id uuid primary key default gen_random_uuid(),
  user_id uuid not null references users(id) on delete cascade,
  type text not null,                     -- e.g. "thumbnail", "index_build"
  payload jsonb not null default '{}'::jsonb,
  status public.job_status not null default 'queued',
  priority int not null default 0,         -- higher = sooner
  attempts int not null default 0,
  max_attempts int not null default 3,
  leased_until timestamptz null,
  lease_owner text not null default '',    -- worker id
  last_error text not null default '',
  run_after timestamptz not null default now(), -- backoff scheduling
  created_at timestamptz not null default now(),
  updated_at timestamptz not null default now()
);

create index if not exists idx_jobs_user_status
  on jobs(user_id, status);

create index if not exists idx_jobs_user_run_after
  on jobs(user_id, run_after);

create index if not exists idx_jobs_lease
  on jobs(status, leased_until);

create or replace function touch_updated_at()
returns trigger language plpgsql as $$
begin new.updated_at = now(); return new; end $$;

drop trigger if exists trg_jobs_touch on jobs;
create trigger trg_jobs_touch
before update on jobs
for each row execute function touch_updated_at();


---

Status transitions (invariants)

queued → leased (worker claims it)

leased → succeeded

leased → failed (maybe retry)

queued|leased → canceled (manual)

Lease expires automatically when leased_until < now(); job becomes eligible again.



---

API surface

Base: /api

Producer endpoints

POST /jobs
body: { type: string, payload?: object, priority?: number, maxAttempts?: number }

GET /jobs?status=&limit=50

GET /jobs/:id

POST /jobs/:id/cancel


Worker endpoints (boring worker protocol)

POST /worker/lease body: { workerId: string, leaseSeconds?: number, limit?: number }
Returns array of leased jobs

POST /worker/:id/succeed body: { workerId: string }

POST /worker/:id/fail body: { workerId: string, error: string, retry?: boolean }


Dashboard endpoints

GET /dashboard/summary
returns counts by status + oldest queued age + recent failures

GET /dashboard/failures?limit=50


Behavior caps

Max jobs per user: 1,000,000 (soft cap; enforce via plan if needed)

Max payload size: 64KB

Lease default: 30 seconds

Max leaseSeconds: 300



---

Safe leasing query (the important part)

Lease must be atomic to avoid multiple workers getting same job.

Approach: SELECT ... FOR UPDATE SKIP LOCKED inside a transaction:

Pseudo-SQL:

begin;

with candidate as (
  select id
  from jobs
  where user_id = $uid
    and status in ('queued','leased')
    and run_after <= now()
    and (status = 'queued' or leased_until <= now())
  order by priority desc, created_at asc
  for update skip locked
  limit $limit
)
update jobs j
set status = 'leased',
    leased_until = now() + make_interval(secs => $leaseSeconds),
    lease_owner = $workerId,
    attempts = case when j.status = 'queued' then j.attempts else j.attempts end
from candidate
where j.id = candidate.id
returning j.*;

commit;

(Attempts increment happens on fail/retry, not on lease.)


---

Retry/backoff rule (server-owned)

On fail with retry:

attempts += 1

If attempts >= max_attempts → set status='failed', keep last_error

Else:

set status='queued'

set run_after = now() + backoff_seconds

backoff: min(300, 2^attempts * 5) seconds (caps at 5 min)



On succeed:

verify lease_owner == workerId and status leased

set status='succeeded', clear lease fields



---

NestJS module layout

src/
  db/
    db.module.ts
    db.service.ts          # pg Pool

  authlite/
    device-key.guard.ts
    user.service.ts

  jobs/
    jobs.module.ts
    jobs.controller.ts
    jobs.service.ts
    dto/
      create-job.dto.ts
      lease.dto.ts
      fail.dto.ts

  dashboard/
    dashboard.module.ts
    dashboard.controller.ts
    dashboard.service.ts


---

Env

.env.example

DATABASE_URL=REDACTED_NEON_URL
PORT=3000


---

Smoke tests

1. Create 10 jobs with varying priority


2. Lease with workerId A limit 3 → gets top 3


3. Lease with workerId B limit 3 → gets next 3 (no overlap)


4. Fail one leased job with retry → returns to queued with run_after in future


5. After run_after passes, it becomes leasable again


6. Succeed a job → appears in succeeded list


7. Dashboard counts match reality




---

Done definition

Done = producer can enqueue, worker can lease safely without duplication, retries/backoff work deterministically, and dashboard endpoints reflect queue health with correct scoping by device identity.
