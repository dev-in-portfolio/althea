---
title: 'Roko''s basilisk'
slug: '00648-roko-s-basilisk'
type: THOUGHT_EXPERIMENT
summary: 'Roko''s basilisk is a thought experiment which states that there could be an artificial superintelligence in the future that, while otherwise benevolent, would punish anyone who knew of its potential existence but did not directly contribute to its advancement or development, in order to incentivize that advancement. It originated in a 2010 post at discussion board LessWrong, a rationalist community web forum.'
tags:
  - paradox
axioms:
  - Assume the rules of the domain apply uniformly.
  - Assume the observerâ€™s criteria remain fixed.
  - Assume classification boundaries stay consistent.
  - Assume the model describes the real case.
  - Assume repeated steps do not change the outcome.
  - Assume no hidden variables are introduced midstream.
contradictions:
  - Two reasonable lines of inference yield opposite conclusions
  - A global rule conflicts with a local judgment
  - A stable resolution appears to violate a starting premise
  - Changing the framing reverses the outcome
  - Intuition and formalism diverge at the same step
related: []
prompts:
  - Which assumption is doing the most hidden work?
  - What changes if you relax the smallest constraint?
  - Does the paradox dissolve or relocate when reframed?
  - What is conserved, and what is sacrificed?
sources:
  - https://en.wikipedia.org/wiki/Roko's_basilisk
order: 648
---
## Overview
Roko's basilisk is a thought experiment which states that there could be an artificial superintelligence in the future that, while otherwise benevolent, would punish anyone who knew of its potential existence but did not directly contribute to its advancement or development, in order to incentivize that advancement. It originated in a 2010 post at discussion board LessWrong, a rationalist community web forum.

## Tension
- Two reasonable lines of inference yield opposite conclusions.
- A global rule conflicts with a local judgment.
- A stable resolution appears to violate a starting premise.
- Changing the framing reverses the outcome.
- Intuition and formalism diverge at the same step.

## Why It Matters
This entry tests how a stable rule-set can yield unstable conclusions under certain assumptions.

## Prompts
- Which assumption is doing the most hidden work?
- What changes if you relax the smallest constraint?
- Does the paradox dissolve or relocate when reframed?
- What is conserved, and what is sacrificed?
